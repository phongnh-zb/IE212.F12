import os
import subprocess
import sys

import happybase
import pandas as pd  # <--- Cáº¦N IMPORT PANDAS

# Setup Ä‘Æ°á»ng dáº«n
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(project_root)

from configs import config


def get_hbase_connection():
    try:
        # TÄƒng timeout náº¿u náº¡p dá»¯ liá»‡u lá»›n
        connection = happybase.Connection(config.HBASE_HOST, port=9090, timeout=60000, autoconnect=True)
        return connection
    except Exception as e:
        print(f"âŒ Lá»—i káº¿t ná»‘i HBase: {e}")
        return None

# --- JOB 1 & 2: Náº¡p output cá»§a MapReduce tá»« HDFS vÃ o báº£ng movies ---
def load_from_hdfs(connection, hdfs_path, column_family, column_name, description):
    print(f"\nğŸš€ Báº¯t Ä‘áº§u náº¡p '{description}' tá»« HDFS: {hdfs_path}")
    
    # Kiá»ƒm tra báº£ng tá»“n táº¡i
    if config.HBASE_TABLE_MOVIES.encode() not in connection.tables():
        print(f"âŒ Lá»—i: Báº£ng '{config.HBASE_TABLE_MOVIES}' khÃ´ng tá»“n táº¡i.")
        return

    table = connection.table(config.HBASE_TABLE_MOVIES)
    
    # Lá»‡nh Ä‘á»c file tá»« HDFS
    hdfs_cmd = f"hdfs dfs -cat {hdfs_path}/part-*"
    
    try:
        process = subprocess.Popen(hdfs_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        batch_size = 1000 # TÄƒng batch size lÃªn má»™t chÃºt Ä‘á»ƒ nhanh hÆ¡n
        batch = table.batch(batch_size=batch_size)
        count = 0
        
        print("   -> Äang Ä‘á»c stream tá»« HDFS vÃ  ghi vÃ o HBase...")
        for line in process.stdout:
            try:
                line_str = line.decode('utf-8').strip()
                if not line_str: continue

                # TÃ¡ch báº±ng dáº¥u TAB (\t) do MapReduce xuáº¥t ra
                parts = line_str.split('\t')
                
                # Fallback dáº¥u pháº©y (Ä‘á» phÃ²ng)
                if len(parts) < 2:
                    parts = line_str.split(',')
                
                if len(parts) >= 2:
                    movie_id = parts[0].strip()
                    value = parts[1].strip()
                    
                    # Ghi vÃ o HBase
                    col_key = f"{column_family}:{column_name}".encode()
                    
                    batch.put(movie_id.encode(), {
                        col_key: value.encode()
                    })
                    count += 1
                    
                    if count % 5000 == 0:
                        print(f"   -> ÄÃ£ xá»­ lÃ½ {count} dÃ²ng...", end='\r')
                        
            except Exception as e:
                continue

        batch.send()
        print(f"\nâœ… HOÃ€N Táº¤T '{description}'! Tá»•ng cá»™ng: {count} dÃ²ng Ä‘Æ°á»£c cáº­p nháº­t.")
        
    except Exception as e:
        print(f"âŒ Lá»—i khi Ä‘á»c HDFS hoáº·c ghi batch: {e}")

# --- JOB 3: TÃ­nh toÃ¡n phÃ¢n bá»‘ rating tá»« CSV vÃ  náº¡p vÃ o báº£ng rating_stats ---
def load_rating_distribution_from_csv(connection):
    description = "PhÃ¢n Bá»‘ Rating ToÃ n Cá»¥c"
    csv_path = os.path.join(config.DATA_DIR_LOCAL, config.RATINGS_FILE)
    # Giáº£ sá»­ báº¡n Ä‘Ã£ Ä‘á»‹nh nghÄ©a HBASE_TABLE_RATING_STATS trong config
    table_name = config.HBASE_TABLE_RATING_STATS 
    row_key = b'GLOBAL_DIST'
    cf = b'info'

    print(f"\nğŸš€ Báº¯t Ä‘áº§u tÃ­nh toÃ¡n vÃ  náº¡p '{description}' tá»« file CSV local: {csv_path}")

    # 1. Kiá»ƒm tra file CSV
    if not os.path.exists(csv_path):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file CSV táº¡i '{csv_path}'. Kiá»ƒm tra láº¡i config.")
        return

    # 2. Kiá»ƒm tra báº£ng HBase
    if table_name.encode() not in connection.tables():
         print(f"âŒ Lá»—i: Báº£ng '{table_name}' chÆ°a tá»“n táº¡i. Vui lÃ²ng táº¡o báº£ng trong HBase Shell trÆ°á»›c: create '{table_name}', '{cf.decode()}'")
         return

    try:
        # 3. DÃ¹ng Pandas Ä‘á»ƒ tÃ­nh toÃ¡n nhanh
        print("   -> Äang Ä‘á»c CSV vÃ  tÃ­nh toÃ¡n báº±ng Pandas (cÃ³ thá»ƒ máº¥t vÃ i giÃ¢y)...")
        # Chá»‰ Ä‘á»c cá»™t 'rating' Ä‘á»ƒ tiáº¿t kiá»‡m RAM
        df = pd.read_csv(csv_path, usecols=['rating'])
        # Äáº¿m sá»‘ lÆ°á»£ng (value_counts) vÃ  sáº¯p xáº¿p theo index (má»©c rating)
        rating_counts = df['rating'].value_counts().sort_index()
        
        print(f"   -> ÄÃ£ tÃ­nh xong. TÃ¬m tháº¥y {len(rating_counts)} má»©c rating khÃ¡c nhau.")
        
        # 4. Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ Put vÃ o HBase
        table = connection.table(table_name)
        hbase_data = {}
        for rating_val, count in rating_counts.items():
            rating_str = str(rating_val)
            col_key = f"{cf.decode()}:{rating_str}".encode('utf-8')
            col_value = str(count).encode('utf-8')
            hbase_data[col_key] = col_value

        # 5. Thá»±c hiá»‡n 1 lá»‡nh Put duy nháº¥t
        print(f"   -> Äang ghi dá»¯ liá»‡u vÃ o báº£ng '{table_name}' vá»›i RowKey '{row_key.decode()}'...")
        table.put(row_key, hbase_data)
        print(f"âœ… HOÃ€N Táº¤T '{description}'!")

    except Exception as e:
        print(f"âŒ Lá»—i khi xá»­ lÃ½ CSV hoáº·c ghi HBase: {e}")

# --- JOB 4 (Má»šI): TÃ­nh toÃ¡n tá»•ng quan há»‡ thá»‘ng vÃ  náº¡p vÃ o báº£ng system_stats ---
def load_system_overview_from_csv(connection):
    description = "Tá»•ng Quan Há»‡ Thá»‘ng (Users, Movies, Ratings)"
    movies_csv_path = os.path.join(config.DATA_DIR_LOCAL, config.MOVIES_FILE)
    ratings_csv_path = os.path.join(config.DATA_DIR_LOCAL, config.RATINGS_FILE)
    
    # Cáº¦N Äáº¢M Báº¢O BIáº¾N NÃ€Y CÃ“ TRONG FILE CONFIG Cá»¦A Báº N
    table_name = config.HBASE_TABLE_SYSTEM_STATS 
    row_key = b'OVERVIEW'
    cf = b'info'

    print(f"\nğŸš€ Báº¯t Ä‘áº§u tÃ­nh toÃ¡n vÃ  náº¡p '{description}' tá»« cÃ¡c file CSV local...")

    # 1. Kiá»ƒm tra cÃ¡c file CSV
    if not os.path.exists(movies_csv_path) or not os.path.exists(ratings_csv_path):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file movies.csv hoáº·c ratings.csv táº¡i thÆ° má»¥c '{config.DATA_DIR_LOCAL}'.")
        return

    # 2. Kiá»ƒm tra báº£ng HBase
    if table_name.encode() not in connection.tables():
         print(f"âŒ Lá»—i: Báº£ng '{table_name}' chÆ°a tá»“n táº¡i. Vui lÃ²ng táº¡o báº£ng trong HBase Shell trÆ°á»›c: create '{table_name}', '{cf.decode()}'")
         return

    try:
        print("   -> Äang Ä‘á»c CSV vÃ  tÃ­nh toÃ¡n tá»•ng quan báº±ng Pandas...")
        
        # a. Äáº¿m sá»‘ phim (Chá»‰ cáº§n Ä‘á»c 1 cá»™t báº¥t ká»³ Ä‘á»ƒ Ä‘áº¿m dÃ²ng)
        movies_df = pd.read_csv(movies_csv_path, usecols=['movieId'])
        movie_count = len(movies_df)
        print(f"      - Tá»•ng sá»‘ phim: {movie_count:,}")

        # b. Äáº¿m sá»‘ rating vÃ  user (Chá»‰ Ä‘á»c cÃ¡c cá»™t cáº§n thiáº¿t)
        ratings_df = pd.read_csv(ratings_csv_path, usecols=['userId', 'rating'])
        rating_count = len(ratings_df)
        user_count = ratings_df['userId'].nunique() # Äáº¿m sá»‘ user duy nháº¥t
        print(f"      - Tá»•ng lÆ°á»£t Ä‘Ã¡nh giÃ¡: {rating_count:,}")
        print(f"      - Tá»•ng ngÆ°á»i dÃ¹ng (unique): {user_count:,}")

        # 3. Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ Put vÃ o HBase
        table = connection.table(table_name)
        
        # Dá»¯ liá»‡u pháº£i Ä‘Æ°á»£c encode sang bytes
        data_to_put = {
            f'{cf.decode()}:user_count'.encode(): str(user_count).encode(),
            f'{cf.decode()}:movie_count'.encode(): str(movie_count).encode(),
            f'{cf.decode()}:rating_count'.encode(): str(rating_count).encode(),
        }

        # 4. Thá»±c hiá»‡n 1 lá»‡nh Put duy nháº¥t
        print(f"   -> Äang ghi dá»¯ liá»‡u vÃ o báº£ng '{table_name}' vá»›i RowKey '{row_key.decode()}'...")
        table.put(row_key, data_to_put)
        
        print(f"âœ… HOÃ€N Táº¤T '{description}'!")

    except Exception as e:
        print(f"âŒ Lá»—i khi tÃ­nh toÃ¡n tá»•ng quan hoáº·c ghi HBase: {e}")


def main():
    # Táº¡o káº¿t ná»‘i má»™t láº§n vÃ  dÃ¹ng chung
    conn = get_hbase_connection()
    if not conn: return

    try:
        # --- CÃC JOB CÅ¨ (Äá»c tá»« HDFS MR Output) ---
        # 1. Náº P AVG RATING
        load_from_hdfs(
            conn, 
            config.HDFS_OUTPUT_AVG, 
            "stats", 
            "avg_rating", 
            "Äiá»ƒm Cá»™ng Äá»“ng (Avg Rating)"
        )

        # 2. Náº P RATING COUNT
        load_from_hdfs(
            conn, 
            config.HDFS_OUTPUT_RATINGS, 
            "stats", 
            "rating_count", 
            "Sá»‘ LÆ°á»£t ÄÃ¡nh GiÃ¡ (Rating Count)"
        )

        # --- CÃC JOB Má»šI (Äá»c tá»« CSV Local Ä‘á»ƒ thá»‘ng kÃª nhanh) ---
        # 3. Náº P RATING DISTRIBUTION
        load_rating_distribution_from_csv(conn)
        
        # 4. Náº P SYSTEM OVERVIEW (Má»šI THÃŠM)
        load_system_overview_from_csv(conn)

    finally:
        # LuÃ´n Ä‘Ã³ng káº¿t ná»‘i cuá»‘i cÃ¹ng
        if conn:
            conn.close()
            print("\nğŸ”Œ ÄÃ£ Ä‘Ã³ng káº¿t ná»‘i HBase.")

if __name__ == "__main__":
    main()