from pyspark.sql.functions import (avg, broadcast, col, collect_list, count,
                                   desc, explode, row_number, split, struct)
from pyspark.sql.window import Window


class ContentBasedRecommender:
    def __init__(self, spark_session):
        self.spark = spark_session
        self.user_profiles = None
        self.movie_profiles = None
        self.final_recs = None

    def train(self, df_ratings, df_movies):
        print("   -> [CBF] Training Optimized for 10M Dataset...")
        
        # 1. T·∫†O USER PROFILE (S·ªû TH√çCH)
        # Ch·ªâ l·∫•y Top 2 th·ªÉ lo·∫°i user th√≠ch nh·∫•t d·ª±a tr√™n phim h·ªç ch·∫•m >= 4.0
        user_movies = df_ratings.filter("rating >= 4.0") \
            .join(df_movies, "movieId") \
            .select("userId", "genres")

        # ƒê·∫øm s·ªë l·∫ßn user xem t·ª´ng th·ªÉ lo·∫°i
        user_genre_counts = user_movies.withColumn("genre", explode(split(col("genres"), r"\|"))) \
            .groupBy("userId", "genre").count()

        # L·∫•y Top 2 th·ªÉ lo·∫°i
        windowUser = Window.partitionBy("userId").orderBy(desc("count"))
        # L∆∞u User Profile (UserId -> Top Genre)
        self.user_profiles = user_genre_counts.withColumn("rank", row_number().over(windowUser)) \
            .filter("rank <= 2") \
            .select("userId", col("genre").alias("top_genre"))
            
        # Optimize: Broadcast User Profile n·∫øu c·∫ßn, nh∆∞ng ·ªü ƒë√¢y ta l∆∞u DataFrame ƒë·ªÉ d√πng sau
        self.user_profiles = self.user_profiles.cache()
        
        # 2. T·∫†O MOVIE PROFILE (CANDIDATE SELECTION)
        
        # B2.1: T√≠nh ƒëi·ªÉm TB v√† s·ªë l∆∞·ª£t vote
        movie_stats = df_ratings.groupBy("movieId") \
            .agg(
                avg("rating").alias("avg_rating"),
                count("rating").alias("vote_count")
            ) \
            .filter("avg_rating >= 3.5") \
            .filter("vote_count >= 50")  # Ch·ªâ l·∫•y phim c√≥ √≠t nh·∫•t 50 l∆∞·ª£t vote (Tr√°nh nhi·ªÖu)

        # B2.2: G√°n th·ªÉ lo·∫°i cho phim v√† l·ªçc Top 50 per Genre
        movies_exploded = df_movies.join(movie_stats, "movieId") \
            .withColumn("genre", explode(split(col("genres"), r"\|")))
        
        windowGenre = Window.partitionBy("genre").orderBy(desc("avg_rating"), desc("vote_count"))
        
        # L∆∞u Movie Profile (Genre -> List Top Movies)
        self.movie_profiles = movies_exploded \
            .withColumn("rank_genre", row_number().over(windowGenre)) \
            .filter("rank_genre <= 50") \
            .select("movieId", "genre", "avg_rating")
            
        self.movie_profiles = self.movie_profiles.cache()

        # 3. GENERATE RECOMMENDATIONS (Cho t·∫≠p User ƒë√£ bi·∫øt)
        # Join User th√≠ch 'Action' v·ªõi Top 50 phim 'Action'
        recs = self.user_profiles.join(broadcast(self.movie_profiles), 
                                    self.user_profiles.top_genre == self.movie_profiles.genre) \
            .select("userId", "movieId", "avg_rating") \
            .distinct()

        # 4. L·∫§Y TOP 10 FINAL
        # L√∫c n√†y d·ªØ li·ªáu ƒë√£ r·∫•t nh·∫π, window function s·∫Ω ch·∫°y nhanh
        windowFinal = Window.partitionBy("userId").orderBy(desc("avg_rating"))
        
        self.final_recs = recs.withColumn("rank", row_number().over(windowFinal)) \
            .filter("rank <= 10") \
            .groupBy("userId") \
            .agg(collect_list(struct(col("movieId"), col("avg_rating").alias("rating"))).alias("recommendations"))
        
        print(f"   -> [CBF] Training Done. User Profiles & Movie Profiles Created.")
        return self

    def evaluate(self, test_data):
        from pyspark.ml.evaluation import RegressionEvaluator
        print("   [CBF] ƒêang ƒë√°nh gi√° tr√™n t·∫≠p Test...")
        
        if self.user_profiles is None or self.movie_profiles is None:
             print("   [CBF] Model ch∆∞a ƒë∆∞·ª£c train. Kh√¥ng th·ªÉ ƒë√°nh gi√°.")
             return {"rmse": float('inf'), "mae": float('inf')}

        # Logic Prediction cho CBF: 
        # N·∫øu Movie thu·ªôc th·ªÉ lo·∫°i Top c·ªßa User -> Predict = Avg Rating c·ªßa Movie ƒë√≥
        # N·∫øu kh√¥ng -> Predict = Global Average (v√≠ d·ª• 3.0)
        
        # Join User Profile
        test_with_profile = test_data.join(self.user_profiles, "userId", "left")
        
        # Predict = Movie's Avg Rating n·∫øu Movie ƒë√≥ c≈©ng thu·ªôc Top Genre c·ªßa User.
        predictions = test_with_profile.join(self.movie_profiles, 
            (test_with_profile.movieId == self.movie_profiles.movieId) & 
            (test_with_profile.top_genre == self.movie_profiles.genre), 
            "left") \
            .select(
                test_with_profile["userId"], 
                test_with_profile["movieId"], 
                col("rating").alias("actual"), 
                col("avg_rating").alias("prediction")
            ).na.fill(3.0, subset=["prediction"]) # Fill 3.0 n·∫øu kh√¥ng t√¨m th·∫•y match
            
        # Do join v·ªõi profile (1 user c√≥ 2 genres) n√™n 1 d√≤ng rating c√≥ th·ªÉ sinh ra 2 d√≤ng prediction
        predictions = predictions.groupBy("userId", "movieId", "actual") \
            .agg(avg("prediction").alias("prediction"))
            
        evaluator_rmse = RegressionEvaluator(metricName="rmse", labelCol="actual", predictionCol="prediction")
        evaluator_mae = RegressionEvaluator(metricName="mae", labelCol="actual", predictionCol="prediction")
        
        rmse = evaluator_rmse.evaluate(predictions)
        mae = evaluator_mae.evaluate(predictions)
        
        print(f"   [CBF] üìä K·∫øt qu·∫£: RMSE={rmse:.4f}, MAE={mae:.4f}")
        return {"rmse": rmse, "mae": mae}

    def get_recommendations(self, k=10):
        return self.final_recs