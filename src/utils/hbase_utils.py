# FILE: src/utils/hbase_utils.py
import os
import sys
from datetime import datetime

import happybase
import pandas as pd
from fpdf import FPDF

# --- SETUP PATH ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(project_root)

from configs import config


def load_ratings_from_hbase(spark):

    from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, LongType
    print("[HBASE] loading rating....")
    connection = None
    BATCH_SIZE = 10000
    schema = StructType([
        StructField("userId", IntegerType(), True),
        StructField("movieId", IntegerType(), True),
        StructField("rating", FloatType(), True),
        StructField("timestamp", LongType(), True),
    ])
    try:
        connection = happybase.Connection(host=config.HBASE_HOST, timeout=60000)
        table = connection.table(config.HBASE_TABLE_RATINGS)
        all_dfs = []
        batch_data = []
        user_count = 0
        total_ratings = 0

        for row_key, row_data in table.scan():
            user_id = int(row_key.decode('utf-8'))

            for col_key, col_val in row_data.items():
                col_family, col_qualifier = col_key.split(b':', 1)

                if col_family == b'r':
                    movie_id = int(col_qualifier.decode('utf-8'))
                    rating = float(col_val.decode('utf-8'))

                    ts_key = b't:' + col_qualifier
                    timestamp = int(row_data.get(ts_key, b'0').decode('utf-8'))

                    batch_data.append((user_id, movie_id, rating, timestamp))
                    total_ratings += 1
            user_count += 1

            if user_count % BATCH_SIZE == 0:
                if batch_data:
                    batch_df = spark.createDataFrame(batch_data, schema)
                    all_dfs.append(batch_df)
                    batch_data = []
                print(f'    ->Processed {user_count:,} users, {total_ratings:,} ratings...')
        if batch_data:
            batch_df = spark.createDataFrame(batch_data, schema)
            all_dfs.append(batch_df)

        connection.close()

        if not all_dfs:
            print("[Hbase] no rating found")
            return None

        print(f'    -> Merging {len(all_dfs)} batches...')
        result_df = all_dfs[0]
        for df in all_dfs[1:]:
            result_df = result_df.union(df)

        print(f"Hbase - loaded {total_ratings:,} ratings")
        return result_df
    except Exception as e:
        print(f"Hbase error - load_rating {e}")
        if connection:
            connection.close()
        return None

def load_movies_from_hbase(spark):
    print("Hbase - loading movies...")
    connection = None
    try:
        connection = happybase.Connection(host=config.HBASE_HOST, timeout=30000)
        table = connection.table(config.HBASE_TABLE_MOVIES)
        data = []
        for row_key, row_data in table.scan():
            movie_id = int(row_key.decode('utf-8'))
            title = row_data.get(b'info:title', b'Unknown').decode('utf-8')
            genres = row_data.get(b'info:genres', b'').decode('utf-8')

            data.append({
                'movieId': movie_id,
                'title': title,
                'genres': genres
            })
        connection.close()

        if not data:
            print("Hbase - No movies found")
            return None

        pdf = pd.DataFrame(data)
        df = spark.createDataFrame(pdf)
        print(f"Hbase - loaded {len(pdf)} movies")
        return df
    except Exception as e:
        print(f"HBase error - load_movie {e}")
        if connection:
            connection.close()
        return None


def load_tags_from_hbase(spark):

    from pyspark.sql.types import StructType, StructField, IntegerType, StringType, LongType

    print("Hbase - loading tags...")
    connection = None
    BATCH_SIZE = 50000
    schema = StructType([
        StructField("userId", IntegerType(), True),
        StructField("movieId", IntegerType(), True),
        StructField("tag", StringType(), True),
        StructField("timestamp", LongType(), True),
    ])

    try:
        connection = happybase.Connection(host=config.HBASE_HOST, timeout=60000)
        table = connection.table(config.HBASE_TABLE_TAGS)

        all_dfs = []
        batch_data = []
        total_tags = 0

        for row_key, row_data in table.scan():
            key_str = row_key.decode('utf-8')

            user_id = None
            movie_id = None
            tag = None
            timestamp = 0

            if b'info:userId' in row_data:
                user_id = int(row_data.get(b'info:userId', b'').decode('utf-8'))
                movie_id = int(row_data.get(b'info:movieId', b'0').decode('utf-8'))
                tag = row_data.get(b'info:tag', b'').decode('utf-8')
                timestamp = int(row_data.get(b'info:timestamp', b'0').decode('utf-8'))
            elif '_' in key_str:
                parts = key_str.split('_')
                if len(parts) >= 2:
                    user_id = int(parts[0])
                    movie_id = int(parts[1])
                    tag = row_data.get(b'info:tag', b'').decode('utf-8')
                    timestamp = int(row_data.get(b'info:timestamp', b'0').decode('utf-8'))
                else:
                    continue

            else:
                user_id = int(key_str)
                for col_key, col_val in row_data.items():
                    if col_key.startswith(b'tag:'):
                        movie_id = int(col_key.split(b':')[1].decode('utf-8'))
                        tag = col_val.decode('utf-8')
                        timestamp = 0

                        if tag:
                            batch_data.append((user_id, movie_id, tag, timestamp))
                            total_tags += 1
                continue

            if tag:
                batch_data.append((user_id, movie_id, tag, timestamp))
                total_tags += 1

            if total_tags > 0 and total_tags % BATCH_SIZE == 0:
                batch_df = spark.createDataFrame(batch_data, schema)
                all_dfs.append(batch_df)
                batch_data = []
                print(f'    ->Processed {total_tags:,} tags...')
        if batch_data:
            batch_df = spark.createDataFrame(batch_data, schema)
            all_dfs.append(batch_df)
        connection.close()

        if not all_dfs:
            print("Hbase - No tags found")
            return None

        print(f"    -> Merging {len(all_dfs)} batches...")

        result_df = all_dfs[0]
        for df in all_dfs[1:]:
            result_df = result_df.union(df)

        print(f"    Loaded {total_tags:,} tags")

        return result_df
    except Exception as e:
        print(f"HBase error - load_tags {e}")
        if connection:
            connection.close()
        return None


def load_all_data_from_hbase(spark):
    print(f"Hbase - loading all data...")
    print("\n" + "-" * 50)
    df_ratings = load_ratings_from_hbase(spark)
    df_movies = load_movies_from_hbase(spark)
    df_tags = load_tags_from_hbase(spark)

    return df_ratings, df_movies, df_tags


class HBaseProvider:
    def __init__(self):
        self.host = config.HBASE_HOST
        self.pool = None
    
    def connect(self):
        # Ch·ªâ t·∫°o pool n·∫øu ch∆∞a c√≥ ho·∫∑c ƒë√£ b·ªã reset
        if not self.pool:
            print(f"üîå [HBase] Connecting to {self.host}...")
            # Autoconnect=True gi√∫p qu·∫£n l√Ω socket t·ªët h∆°n
            self.pool = happybase.ConnectionPool(size=3, host=self.host, timeout=30000, autoconnect=True)
            
    def get_font_path():
        possible_paths = [
            "fonts/DejaVuSans.ttf"
        ]
        for path in possible_paths:
            if os.path.exists(path):
                return path
        return None

    def get_recommendations(self, user_id, model_name=None):
        self.connect()
        results = []
        try:
            with self.pool.connection() as connection:
                rec_table = connection.table(config.HBASE_TABLE_RECS)
                row = rec_table.row(str(user_id).encode('utf-8'))
                
                # Determine column to use
                col_key = b'info:movieIds'
                if model_name:
                    col_key = f"info:{model_name}".lower().encode('utf-8')
                
                if not row or col_key not in row: return []
                
                raw_string = row[col_key].decode('utf-8')
                rec_items = []
                movie_ids = []
                for item in raw_string.split(','):
                    try:
                        mid, pred_score = item.split(':')
                        rec_items.append((mid, pred_score))
                        movie_ids.append(mid)
                    except ValueError: continue
                
                if not movie_ids: return []

                movie_table = connection.table(config.HBASE_TABLE_MOVIES)
                rows = movie_table.rows([mid.encode('utf-8') for mid in movie_ids])
                movies_info = {k.decode(): v for k, v in rows}

                for mid, pred_score in rec_items:
                    data = movies_info.get(mid)
                    if data:
                        # X·ª≠ l√Ω Avg Rating
                        avg_rating_bytes = data.get(b'stats:avg_rating')
                        avg_rating = float(avg_rating_bytes.decode('utf-8')) if avg_rating_bytes else 0.0
                        
                        results.append({
                            "movieId": mid,
                            "title": data.get(b'info:title', b'Unknown').decode('utf-8'),
                            "genres": data.get(b'info:genres', b'Unknown').decode('utf-8'),
                            "avg_rating": avg_rating,
                            "pred_rating": float(pred_score)
                        })
            return results
        except Exception as e:
            print(f"!!! [HBase Error - get_recommendations] {e}")
            self.pool = None # Reset pool ƒë·ªÉ k·∫øt n·ªëi l·∫°i l·∫ßn sau
            return []

    def get_movie_details(self, movie_id):
        self.connect()
        try:
            with self.pool.connection() as connection:
                table = connection.table(config.HBASE_TABLE_MOVIES)
                row = table.row(str(movie_id).encode('utf-8'))
                
                if not row: return None
                
                avg_rating_bytes = row.get(b'stats:avg_rating')
                rating_count_bytes = row.get(b'stats:rating_count')
                
                return {
                    'movieId': movie_id,
                    'title': row.get(b'info:title', b'Unknown').decode('utf-8'),
                    'genres': row.get(b'info:genres', b'--').decode('utf-8'),
                    'avg_rating': float(avg_rating_bytes.decode('utf-8')) if avg_rating_bytes else 0.0,
                    'rating_count': int(rating_count_bytes.decode('utf-8')) if rating_count_bytes else 0,
                    "tags": row.get(b'info:tags', b'').decode('utf-8')
                }
        except Exception as e:
            print(f"!!! [HBase Error - get_movie_details] {e}")
            self.pool = None # Reset pool
            return None

    # H√†m l·∫•y danh s√°ch rating c·ªßa user (d·∫°ng dict)
    def get_user_ratings(self, user_id):
        self.connect()
        user_ratings = {}
        try:
            with self.pool.connection() as connection:
                table = connection.table(config.HBASE_TABLE_RATINGS)
                row = table.row(str(user_id).encode('utf-8'))
                if row:
                    for key, val in row.items():
                        if b':' in key:
                            fam, mid_bytes = key.split(b':', 1)
                            if fam == b'r': 
                                mid = mid_bytes.decode('utf-8')
                                rating = val.decode('utf-8')
                                user_ratings[mid] = rating
            return user_ratings
        except Exception as e:
            print(f"!!! [HBase Error - get_user_ratings] {e}")
            self.pool = None # Reset pool
            return {}

    # H√†m l·∫•y l·ªãch s·ª≠ chi ti·∫øt cho Tab 2
    def get_user_history_detailed(self, user_id):
        self.connect()
        history = []
        ratings_map = {} 
        timestamps_map = {}
        try:
            with self.pool.connection() as connection:
                rating_table = connection.table(config.HBASE_TABLE_RATINGS)
                row = rating_table.row(str(user_id).encode('utf-8'))
                if row:
                    for key, val in row.items():
                        if b':' in key:
                            fam, mid_bytes = key.split(b':', 1)
                            mid = mid_bytes.decode('utf-8')
                            if fam == b'r':
                                ratings_map[mid] = float(val.decode('utf-8'))
                            elif fam == b't':
                                timestamps_map[mid] = int(val.decode('utf-8'))
                
                if not ratings_map: return []
                
                movie_ids = list(ratings_map.keys())
                movie_table = connection.table(config.HBASE_TABLE_MOVIES)
                movie_rows = movie_table.rows([m.encode('utf-8') for m in movie_ids])
                
                movie_info = {}
                for key, data in movie_rows:
                    mid = key.decode('utf-8')
                    movie_info[mid] = {
                        'title': data.get(b'info:title', b'Unknown').decode('utf-8'),
                        'genres': data.get(b'info:genres', b'--').decode('utf-8')
                    }
                
                for mid, rating in ratings_map.items():
                    info = movie_info.get(mid, {'title': f"ID:{mid}", 'genres': 'Unknown'})
                    ts = timestamps_map.get(mid, 0)
                    date_str = datetime.fromtimestamp(ts).strftime('%Y-%m-%d') if ts > 0 else "--"
                    
                    history.append({
                        "movieId": mid,
                        "title": info['title'],
                        "genres": info['genres'],
                        "rating": rating,
                        "date": date_str
                    })
            
            # S·∫Øp x·∫øp theo ng√†y m·ªõi nh·∫•t -> c≈© nh·∫•t
            history.sort(key=lambda x: (x['date'], x['rating']), reverse=True)
            return history
        except Exception as e:
            print(f"!!! [HBase Error - get_user_history] {e}")
            self.pool = None # Reset pool
            return []

    def get_genre_stats(self):
        self.connect()
        data = []
        try:
            with self.pool.connection() as connection:
                tables = [t.decode('utf-8') for t in connection.tables()]
                if config.HBASE_TABLE_GENRE_STATS not in tables: return []
                table = connection.table(config.HBASE_TABLE_GENRE_STATS)
                for key, value in table.scan():
                    genre = key.decode('utf-8')
                    count_val = value.get(b'info:count')
                    if count_val:
                        data.append({"genre": genre, "count": int(count_val.decode('utf-8'))})
            data.sort(key=lambda x: x['count'], reverse=True)
            return data
        except Exception as e:
            print(f"!!! [HBase Error - get_genre_stats] {e}")
            self.pool = None # Reset pool
            return []

    def scan_recommendations(self, limit=100):
        self.connect()
        results = []
        all_movie_ids = set()
        try:
            with self.pool.connection() as connection:
                rec_table = connection.table(config.HBASE_TABLE_RECS)
                movie_table = connection.table(config.HBASE_TABLE_MOVIES)
                temp_rows = []
                for key, data in rec_table.scan(limit=limit):
                    user_id = key.decode('utf-8')
                    raw_val = data.get(b'info:movieIds', b'').decode('utf-8')
                    if raw_val:
                        items = []
                        for item in raw_val.split(','):
                            try:
                                mid, score = item.split(':')
                                items.append((mid, score))
                                all_movie_ids.add(mid)
                            except ValueError: continue
                        temp_rows.append({"user_id": user_id, "items": items})
                movie_map = {}
                if all_movie_ids:
                    movie_rows = movie_table.rows([mid.encode('utf-8') for mid in all_movie_ids])
                    for key, data in movie_rows:
                        movie_map[key.decode('utf-8')] = data.get(b'info:title', b'Unknown').decode('utf-8')
                for row in temp_rows:
                    formatted_recs = []
                    for mid, score in row['items']:
                        title = movie_map.get(mid, f"ID:{mid}")
                        formatted_recs.append(f"{title} ({float(score):.1f}‚òÖ)")
                    results.append({
                        "User ID": row['user_id'],
                        "Total": len(row['items']),
                        "Recommendations (Details)": " | ".join(formatted_recs)
                    })
            return results
        except Exception as e:
            print(f"!!! [HBase Error - scan_recommendations] {e}")
            self.pool = None # Reset pool
            return []

    def save_model_metrics(self, model_name, metrics, is_raw_data=False):
        self.connect()
        try:
            with self.pool.connection() as connection:
                # S·ª≠ d·ª•ng t√™n b·∫£ng t·ª´ config
                table_name = config.HBASE_TABLE_MODEL_METRICS
                if table_name.encode() not in connection.tables():
                    print(f"‚ö†Ô∏è [HBase] Warning: Table '{table_name}' does not exist. Skipping save.")
                    return

                table = connection.table(table_name)
                row_key = model_name.encode()
                data_to_put = {}

                if is_raw_data:
                    # --- LOGIC M·ªöI: X·ª≠ l√Ω d·ªØ li·ªáu th√¥ (cho LATEST_RUN) ---
                    # Input metrics d·∫°ng: {'b:winner_model': 'als', 'b:rmse': 0.8973, ...}
                    # Key ƒë√£ bao g·ªìm Column Family.
                    for col_str, value in metrics.items():
                        # Encode key (v√≠ d·ª•: 'b:winner_model' -> b'b:winner_model')
                        col_key_bytes = col_str.encode('utf-8')
                        # Encode value sang string r·ªìi sang bytes
                        col_val_bytes = str(value).encode('utf-8')
                        data_to_put[col_key_bytes] = col_val_bytes
                else:
                    # --- LOGIC C≈®: X·ª≠ l√Ω metrics chu·∫©n (cho c√°c model th∆∞·ªùng) ---
                    # Input metrics d·∫°ng: {'rmse': 0.8973, 'mae': 0.685}
                    # T·ª± ƒë·ªông g√°n v√†o Column Family 'info' v√† th√™m timestamp.
                    data_to_put = {
                        b'info:rmse': str(metrics.get('rmse', 0.0)).encode(),
                        b'info:mae': str(metrics.get('mae', 0.0)).encode(),
                        b'info:updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S').encode()
                    }
                
                # Th·ª±c hi·ªán ghi v√†o HBase
                table.put(row_key, data_to_put)
                print(f"‚úÖ [HBase] Saved data for RowKey: '{model_name}'")

        except Exception as e:
            print(f"!!! [HBase Error - save_model_metrics] {e}")

    def get_all_model_metrics(self):
        """
        L·∫•y t·∫•t c·∫£ metrics c·ªßa c√°c model ƒë·ªÉ hi·ªÉn th·ªã dashboard.
        T·ª± ƒë·ªông x·ª≠ l√Ω l·ªói d·ªØ li·ªáu v√† fallback gi·ªØa c√°c column families.
        """
        self.connect()
        results = []
        try:
            with self.pool.connection() as connection:
                tables = [t.decode('utf-8') for t in connection.tables()]
                if config.HBASE_TABLE_MODEL_METRICS not in tables:
                    return []
                
                table = connection.table(config.HBASE_TABLE_MODEL_METRICS)
                for key, data in table.scan():
                    model_name = key.decode('utf-8')
                    
                    # Helper l·∫•y gi√° tr·ªã an to√†n t·ª´ nhi·ªÅu family
                    def get_safe_val(col_name, default='0'):
                        # ∆Øu ti√™n l·∫•y t·ª´ 'info' (cho c√°c model l·∫ª), sau ƒë√≥ th·ª≠ 'b' (cho LATEST_RUN)
                        val = data.get(f'info:{col_name}'.encode())
                        if val is None:
                            val = data.get(f'b:{col_name}'.encode())
                        return val.decode('utf-8') if val else default

                    try:
                        rmse_val = float(get_safe_val('rmse'))
                        mae_val = float(get_safe_val('mae'))
                        updated_at = get_safe_val('updated_at', '--')
                        if updated_at == '--': # Th·ª≠ l·∫•y timestamp n·∫øu l√† LATEST_RUN
                            updated_at = get_safe_val('timestamp', '--')

                        results.append({
                            "model": model_name,
                            "rmse": rmse_val,
                            "mae": mae_val,
                            "updated_at": updated_at
                        })
                    except (ValueError, TypeError) as conv_err:
                        print(f"‚ö†Ô∏è [HBase] L·ªói chuy·ªÉn ƒë·ªïi data cho model {model_name}: {conv_err}")
                        continue
            return results
        except Exception as e:
            print(f"!!! [HBase Error - get_all_model_metrics] {e}")
            self.pool = None
            return []
        
    def get_top_rated_movies(self, limit=10):
        """L·∫•y danh s√°ch phim c√≥ l∆∞·ª£t ƒë√°nh gi√° cao nh·∫•t ƒë·ªÉ v·∫Ω chart Top 10"""
        self.connect()
        movies_data = []
        try:
            with self.pool.connection() as connection:
                table = connection.table(config.HBASE_TABLE_MOVIES)
                # Qu√©t b·∫£ng movies ƒë·ªÉ l·∫•y c·ªôt rating_count t·ª´ k·∫øt qu·∫£ MapReduce
                for key, data in table.scan():
                    count_bytes = data.get(b'stats:rating_count', b'0')
                    title_bytes = data.get(b'info:title', b'Unknown')
                    
                    count = int(count_bytes.decode('utf-8'))
                    if count > 0:
                        movies_data.append({
                            'title': title_bytes.decode('utf-8'), 
                            'count': count
                        })
            
            # Top phim ph·ªï bi·∫øn nh·∫•t
            import pandas as pd
            if not movies_data:
                return pd.DataFrame(columns=['title', 'count'])
            df = pd.DataFrame(movies_data).sort_values(by='count', ascending=False)
            return df.head(limit)
        except Exception as e:
            print(f"!!! [HBase Error - get_top_rated_movies] {e}")
            import pandas as pd
            return pd.DataFrame(columns=['title', 'count'])

    def get_rating_distribution(self):
        """
        L·∫•y ph√¢n b·ªë s·ªë l∆∞·ª£ng theo m·ª©c ƒëi·ªÉm (0.5 - 5.0) t·ª´ HBase.
        D·ªØ li·ªáu n√†y ƒë∆∞·ª£c t√≠nh to√°n tr∆∞·ªõc v√† l∆∞u trong b·∫£ng th·ªëng k√™.
        """
        # 1. T√™n b·∫£ng v√† RowKey ch·ª©a d·ªØ li·ªáu th·ªëng k√™ ƒë√£ t√≠nh tr∆∞·ªõc
        # (B·∫°n n√™n ƒë∆∞a t√™n b·∫£ng v√†o file config thay v√¨ hardcode)
        ROW_KEY = b'GLOBAL_DIST'
        COLUMN_FAMILY = b'info'

        data_points = []
        
        # Danh s√°ch c√°c m·ª©c rating chu·∫©n c·∫ßn hi·ªÉn th·ªã ƒë·ªÉ ƒë·∫£m b·∫£o th·ª© t·ª±
        expected_ratings = ["0.5", "1.0", "1.5", "2.0", "2.5", "3.0", "3.5", "4.0", "4.5", "5.0"]

        try:
            # 2. S·ª≠ d·ª•ng connection pool ƒë·ªÉ k·∫øt n·ªëi an to√†n
            # Gi·∫£ ƒë·ªãnh self.pool l√† happybase.ConnectionPool ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
            with self.pool.connection() as connection:
                table = connection.table(config.HBASE_TABLE_RATING_STATS)
                
                # 3. Th·ª±c hi·ªán Get (l·∫•y 1 d√≤ng duy nh·∫•t) - R·∫•t nhanh
                row_data = table.row(ROW_KEY)

                # row_data s·∫Ω l√† m·ªôt dict d·∫°ng: {b'info:0.5': b'1200', b'info:1.0': b'3500', ...}
                
                if not row_data:
                    print(f"Warning: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu th·ªëng k√™ cho key {ROW_KEY}")
                    # Tr·∫£ v·ªÅ danh s√°ch r·ªóng v·ªõi count 0 n·∫øu ch∆∞a c√≥ d·ªØ li·ªáu
                    return [{"rating": r, "count": 0} for r in expected_ratings]

                # 4. X·ª≠ l√Ω d·ªØ li·ªáu tr·∫£ v·ªÅ
                for rating_str in expected_ratings:
                    # T·∫°o key ƒë·ªÉ lookup trong dictionary k·∫øt qu·∫£ (v√≠ d·ª•: b'info:3.5')
                    hbase_col_key = f"{COLUMN_FAMILY.decode()}:{rating_str}".encode('utf-8')
                    
                    # L·∫•y gi√° tr·ªã count (d·∫°ng bytes), m·∫∑c ƒë·ªãnh l√† b'0' n·∫øu kh√¥ng c√≥ rating ƒë√≥
                    count_bytes = row_data.get(hbase_col_key, b'0')
                    
                    # Convert bytes sang int
                    count_val = int(count_bytes.decode('utf-8'))
                    
                    data_points.append({
                        "rating": rating_str,
                        "count": count_val
                    })
                    
        except Exception as e:
            print(f"Error getting rating distribution from HBase: {e}")
            # Trong tr∆∞·ªùng h·ª£p l·ªói, c√≥ th·ªÉ tr·∫£ v·ªÅ d·ªØ li·ªáu m·∫∑c ƒë·ªãnh ƒë·ªÉ kh√¥ng crash app
            return [{"rating": r, "count": 0} for r in expected_ratings]

        return data_points
    
    def get_system_overview(self):
        """
        L·∫•y s·ªë li·ªáu t·ªïng quan h·ªá th·ªëng.
        - Counts (Users, Movies, Ratings) -> t·ª´ b·∫£ng 'system_stats'
        - Metrics (RMSE, MAE) -> t·ª´ b·∫£ng 'model_metrics' (row ID: 'LATEST')
        """
        self.connect()

        # 1. L·∫§Y T√äN C√ÅC B·∫¢NG T·ª™ CONFIG
        STATS_TABLE = config.HBASE_TABLE_SYSTEM_STATS
        MODEL_METRICS_TABLE = config.HBASE_TABLE_MODEL_METRICS

        FAMILY = b'info'

        # D·ªØ li·ªáu m·∫∑c ƒë·ªãnh
        overview_data = {
            'user_count': 'N/A', 'movie_count': 'N/A', 'rating_count': 'N/A',
            'rmse_score': 'N/A', 'rmse_delta': None
        }

        if not self.pool: return overview_data

        try:
            with self.pool.connection() as connection:
                # ===================================================
                # 1. L·∫•y Counts t·ª´ system_stats
                # ===================================================
                if STATS_TABLE.encode() in connection.tables():
                    table_stats = connection.table(STATS_TABLE)
                    # RowKey c·ªë ƒë·ªãnh cho th·ªëng k√™ t·ªïng quan
                    row_stats = table_stats.row(b'OVERVIEW')

                    if row_stats:
                        def get_fmt_int(col):
                            val = row_stats.get(f'{FAMILY.decode()}:{col}'.encode())
                            return f"{int(val):,}" if val and val.isdigit() else 'N/A'

                        overview_data['user_count'] = get_fmt_int('user_count')
                        overview_data['movie_count'] = get_fmt_int('movie_count')
                        overview_data['rating_count'] = get_fmt_int('rating_count')

                # ===================================================
                # 2. L·∫•y RMSE t·ª´ model_metrics
                # ===================================================
                if MODEL_METRICS_TABLE.encode() in connection.tables():
                    table_metrics = connection.table(MODEL_METRICS_TABLE)
                    # Gi·∫£ ƒë·ªãnh: Lu√¥n c√≥ 1 row v·ªõi key 'LATEST_RUN' ch·ª©a metrics model hi·ªán t·∫°i
                    row_metrics = table_metrics.row(b'LATEST_RUN')

                    if row_metrics:
                        def get_str(col):
                            val = row_metrics.get(f'{FAMILY.decode()}:{col}'.encode())
                            return val.decode('utf-8') if val else 'N/A'

                        # L·∫•y RMSE hi·ªán t·∫°i
                        overview_data['rmse_score'] = get_str('rmse')

                        # T√≠nh to√°n Delta (N·∫øu c√≥ l∆∞u rmse_prev)
                        rmse_prev_str = get_str('rmse_prev')
                        current_rmse_str = overview_data['rmse_score']

                        if current_rmse_str != 'N/A' and rmse_prev_str != 'N/A':
                            try:
                                delta = float(current_rmse_str) - float(rmse_prev_str)
                                # Format: d·∫•u +/-, 4 s·ªë th·∫≠p ph√¢n. V√≠ d·ª•: -0.0150
                                overview_data['rmse_delta'] = f"{delta:+.4f}"
                            except ValueError: pass
                    else:
                         print(f"‚ÑπÔ∏è Info: Ch∆∞a c√≥ d·ªØ li·ªáu model 'LATEST' trong b·∫£ng '{MODEL_METRICS_TABLE}'.")
                else:
                    print(f"‚ö†Ô∏è Warning: B·∫£ng '{MODEL_METRICS_TABLE}' ch∆∞a ƒë∆∞·ª£c t·∫°o.")


        except Exception as e:
            print(f"‚ùå L·ªói ngo·∫°i l·ªá khi l·∫•y d·ªØ li·ªáu t·ªïng quan: {e}")

        return overview_data
    
    def get_latest_run_info(self):
        """
        L·∫•y th√¥ng tin v·ªÅ model chi·∫øn th·∫Øng (Winner) trong l·∫ßn train g·∫ßn nh·∫•t.
        ƒê·ªçc t·ª´ RowKey 'LATEST_RUN' trong b·∫£ng model_metrics.
        """
        self.connect()
        # Gi√° tr·ªã m·∫∑c ƒë·ªãnh
        latest_info = {
            'winner_model': 'N/A',
            'rmse': 'N/A',
            'timestamp': 'N/A'
        }

        try:
            with self.pool.connection() as connection:
                # Ki·ªÉm tra b·∫£ng metrics c√≥ t·ªìn t·∫°i kh√¥ng
                tables = [t.decode('utf-8') for t in connection.tables()]
                if config.HBASE_TABLE_MODEL_METRICS not in tables:
                    return latest_info
                
                table = connection.table(config.HBASE_TABLE_MODEL_METRICS)
                # RowKey ƒë·∫∑c bi·ªát ta ƒë√£ quy ∆∞·ªõc
                row = table.row(b'LATEST_RUN')

                if row:
                    # Helper l·∫•y d·ªØ li·ªáu an to√†n (l∆∞u √Ω family 'b' cho benchmark/info)
                    # N·∫øu l√∫c save b·∫°n d√πng 'info', h√£y s·ª≠a 'b' th√†nh 'info' ·ªü ƒë√¢y
                    def get_val(col_name):
                        # Th·ª≠ l·∫•y t·ª´ family 'b' tr∆∞·ªõc (nh∆∞ code training), n·∫øu kh√¥ng c√≥ th·ª≠ 'info'
                        val = row.get(f'b:{col_name}'.encode())
                        if not val:
                             val = row.get(f'info:{col_name}'.encode())
                        return val.decode('utf-8') if val else 'N/A'

                    latest_info['winner_model'] = get_val('winner_model').upper()
                    
                    rmse_str = get_val('rmse')
                    if rmse_str != 'N/A':
                        try:
                            # L√†m tr√≤n 4 ch·ªØ s·ªë
                            latest_info['rmse'] = f"{float(rmse_str):.4f}"
                        except:
                            latest_info['rmse'] = rmse_str
                    
                    latest_info['timestamp'] = get_val('timestamp')
        
        except Exception as e:
            print(f"!!! [HBase Error - get_latest_run_info] {e}")
            self.pool = None

        return latest_info
    
    def generate_pdf_report(self, metrics_data, genre_data, system_info):
        pdf = FPDF()
        pdf.add_page()
        
        # --- C·∫§U H√åNH FONT TI·∫æNG VI·ªÜT (QUAN TR·ªåNG) ---
        # 1. X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n file font
        # ƒêi t·ª´ file hi·ªán t·∫°i (hbase_utils.py) -> ra utils -> ra src -> v√†o fonts
        font_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'fonts', 'DejaVuSans.ttf')
        
        # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(font_path):
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y font t·∫°i: {font_path}")
            # Fallback v·ªÅ font m·∫∑c ƒë·ªãnh (s·∫Ω l·ªói font ti·∫øng Vi·ªát nh∆∞ng kh√¥ng crash app)
            pdf.set_font("Arial", 'B', 16)
            pdf.cell(0, 10, txt="BAO CAO TONG QUAN (LOI FONT - THIEU FILE TTF)", ln=True, align='C')
            return bytes(pdf.output())

        # 2. ƒêƒÉng k√Ω font Unicode
        # 'DejaVu' l√† t√™n ta t·ª± ƒë·∫∑t ƒë·ªÉ g·ªçi sau n√†y, uni=True b·∫≠t ch·∫ø ƒë·ªô Unicode
        pdf.add_font('DejaVu', '', font_path)
        
        # 3. Set font ƒë√£ ƒëƒÉng k√Ω
        pdf.set_font('DejaVu', '', 16)
        
        # --- N·ªòI DUNG B√ÅO C√ÅO ---
        pdf.cell(0, 10, txt="B√ÅO C√ÅO T·ªîNG QUAN H·ªÜ TH·ªêNG G·ª¢I √ù PHIM TH√îNG MINH", ln=True, align='C')
        
        pdf.set_font('DejaVu', '', 10)
        pdf.cell(0, 10, txt=f"Ng√†y xu·∫•t: {datetime.now().strftime('%d/%m/%Y %H:%M')}", ln=True, align='C')
        pdf.ln(5)

        # 1. QUY M√î D·ªÆ LI·ªÜU
        # L·∫•y d·ªØ li·ªáu an to√†n t·ª´ dict system_info
        u_cnt = system_info.get('user_count', 'N/A')
        m_cnt = system_info.get('movie_count', 'N/A')
        r_cnt = system_info.get('rating_count', 'N/A')

        pdf.set_font('DejaVu', '', 12)
        pdf.cell(0, 10, txt="1. Quy m√¥ D·ªØ li·ªáu (MovieLens Dataset):", ln=True)
        
        pdf.set_font('DejaVu', '', 11)
        pdf.cell(0, 8, txt=f"- T·ªïng s·ªë Ratings ƒë√£ x·ª≠ l√Ω: {r_cnt}", ln=True)
        pdf.cell(0, 8, txt=f"- T·ªïng s·ªë Phim trong kho: {m_cnt}", ln=True)
        pdf.cell(0, 8, txt=f"- S·ªë l∆∞·ª£ng ng∆∞·ªùi d√πng: {u_cnt}", ln=True)
        pdf.ln(5)

        # 2. HI·ªÜU NƒÇNG M√î H√åNH
        pdf.set_font('DejaVu', '', 12)
        pdf.cell(0, 10, txt="2. K·∫øt qu·∫£ Hu·∫•n luy·ªán v√† ƒê√°nh gi√° (Accuracy):", ln=True)
        
        pdf.set_font('DejaVu', '', 11)
        if metrics_data:
            for m in metrics_data:
                # B·ªè qua d√≤ng LATEST_RUN
                if m.get('model') == 'LATEST_RUN': continue
                
                name = m.get('model', 'Unknown').upper()
                rmse = m.get('rmse', 0.0)
                mae = m.get('mae', 0.0)
                pdf.cell(0, 8, txt=f"- Model {name}: RMSE = {rmse:.4f} | MAE = {mae:.4f}", ln=True)
        else:
            pdf.cell(0, 8, txt="- Ch∆∞a c√≥ d·ªØ li·ªáu metrics.", ln=True)

        # 3. TH·ªêNG K√ä TH·ªÇ LO·∫†I
        pdf.ln(5)
        pdf.set_font('DejaVu', '', 12)
        pdf.cell(0, 10, txt="3. Top Th·ªÉ lo·∫°i ph·ªï bi·∫øn:", ln=True)
        pdf.set_font('DejaVu', '', 11)
        
        if genre_data:
            for g in genre_data[:3]:
                pdf.cell(0, 8, txt=f"- {g['genre']}: {g['count']} phim", ln=True)

        # FOOTER
        pdf.ln(10)
        pdf.set_font('DejaVu', '', 10)
        pdf.multi_cell(0, 6, txt="Ghi ch√∫: RMSE c√†ng th·∫•p th√¨ ƒë·ªô ch√≠nh x√°c d·ª± b√°o c√†ng cao.")

        return bytes(pdf.output())